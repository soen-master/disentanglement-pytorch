0
Pre-Processing CelebA
labels (202599, 32)
All classes percentages: [0.26557880344917795, 0.05174260484997458, 0.14175785665279692, 0.06906253239157152, 0.11322365855705112, 0.10248323042068322, 0.05496078460407011, 0.04944743063884817, 0.0651335890108046, 0.08660950942502184]
Initialized GrayVAE_Join model
## Initializing Train indexes
->path chosen:: logs/celebA__GrayVAE_Join__2022_04/30-21-56
Losses: {'total_vae': tensor(16509.4375, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(8537.3613, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(1.0462, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(2318.2654, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(5652.7656, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(12657.4424, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(7057.3984, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(593.5911, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(2144.7668, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2861.6863, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(12092.8770, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6842.0874, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(647.8220, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1956.3511, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2646.6169, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11919.2363, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6742.2788, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(708.9263, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1956.0730, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2511.9583, device='cuda:0', grad_fn=<MulBackward0>)}
[0:1619]  loss_total_vae=11725.704  loss_recon=6630.887  loss_kld=705.561  loss_prediction=1800.133  loss_true_values=2589.124  loss_total_vae_epoch=12713.629  
tracking changes
Saved model at epoch 1
Losses: {'total_vae': tensor(11796.8828, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6746.1465, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(718.4175, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1883.5364, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2448.7825, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11681.9492, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6696.5986, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(762.9340, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1744.8020, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2477.6145, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11704.4863, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6778.2124, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(794.8962, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1650.4592, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2480.9192, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11419.6953, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6680.3594, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(823.5980, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1602.9833, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2312.7549, device='cuda:0', grad_fn=<MulBackward0>)}
[1:3239]  loss_total_vae=11423.023  loss_recon=6712.301  loss_kld=744.251  loss_prediction=1461.588  loss_true_values=2504.884  loss_total_vae_epoch=11669.397  
tracking changes
Saved model at epoch 2
Losses: {'total_vae': tensor(11527.7578, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6723.2236, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(791.9074, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1601.9067, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2410.7209, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11476.6592, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6693.6284, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(788.2343, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1595.8829, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2398.9131, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11500.3193, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6644.1631, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(766.0745, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1589.5839, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2500.4978, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11284.0889, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6565.4668, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(808.3540, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1565.4487, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2344.8193, device='cuda:0', grad_fn=<MulBackward0>)}
[2:4859]  loss_total_vae=11388.984  loss_recon=6653.535  loss_kld=801.002  loss_prediction=1495.247  loss_true_values=2439.201  loss_total_vae_epoch=11394.949  
tracking changes
Saved model at epoch 3
Losses: {'total_vae': tensor(11097.5020, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6649.3696, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(785.1709, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1415.8685, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2247.0933, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11219.3057, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6721.4785, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(813.5071, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1408.4792, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2275.8406, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11220.5547, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6699.5781, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(856.8467, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1405.4374, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2258.6926, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11120.4971, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6596.4209, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(842.8796, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1386.5616, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2294.6348, device='cuda:0', grad_fn=<MulBackward0>)}
[3:6479]  loss_total_vae=11423.223  loss_recon=6710.753  loss_kld=823.452  loss_prediction=1532.004  loss_true_values=2357.014  loss_total_vae_epoch=11241.393  
tracking changes
Saved model at epoch 4
Losses: {'total_vae': tensor(11095.5977, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6731.9624, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(814.7991, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1287.0057, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2261.8298, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10960.6426, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6475.0156, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(806.2473, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1327.5461, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2351.8337, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11302.7051, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6817.1562, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(819.5510, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1322.2031, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2343.7952, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11321.3984, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6689.5498, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(797.0867, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1443.6875, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2391.0742, device='cuda:0', grad_fn=<MulBackward0>)}
[4:8099]  loss_total_vae=11062.988  loss_recon=6610.353  loss_kld=780.106  loss_prediction=1377.599  loss_true_values=2294.930  loss_total_vae_epoch=11139.500  
tracking changes
Saved model at epoch 5
Losses: {'total_vae': tensor(11168.5107, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6677.8726, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(767.8655, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1424.1843, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2298.5881, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11155.0918, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6682.6382, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(791.6131, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1388.7578, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2292.0823, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10881.7900, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6462.8535, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(837.7258, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1309.5852, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2271.6260, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10991.8525, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6745.3818, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(818.2152, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1146.3727, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2281.8828, device='cuda:0', grad_fn=<MulBackward0>)}
[5:9719]  loss_total_vae=11107.988  loss_recon=6586.187  loss_kld=820.880  loss_prediction=1397.167  loss_true_values=2303.755  loss_total_vae_epoch=11065.839  
tracking changes
Saved model at epoch 6
Losses: {'total_vae': tensor(11032.8467, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6673.4673, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(806.3162, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1306.7443, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2246.3181, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10928.5107, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6637.7446, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(848.2602, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1248.4840, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2194.0212, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11013.3291, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6490.3672, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(873.1278, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1411.4702, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2238.3645, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10977.8857, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6673.6426, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(792.8477, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1191.2642, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2320.1318, device='cuda:0', grad_fn=<MulBackward0>)}
[6:11339]  loss_total_vae=10932.920  loss_recon=6682.801  loss_kld=820.192  loss_prediction=1264.671  loss_true_values=2165.255  loss_total_vae_epoch=11007.738  
tracking changes
Saved model at epoch 7
Losses: {'total_vae': tensor(10860.9746, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6607.8496, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(796.9634, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1221.0573, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2235.1040, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11394.4131, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6819.6387, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(811.0370, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1396.7046, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2367.0325, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10956.2559, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6793.2061, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(825.9829, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1254.6230, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2082.4431, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10593.2949, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6397.3950, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(804.4263, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1211.5842, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2179.8896, device='cuda:0', grad_fn=<MulBackward0>)}
[7:12959]  loss_total_vae=11126.837  loss_recon=6634.198  loss_kld=819.164  loss_prediction=1443.369  loss_true_values=2230.106  loss_total_vae_epoch=10959.589  
tracking changes
Saved model at epoch 8
Losses: {'total_vae': tensor(10918.8232, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6674.3955, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(807.4059, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1230.1021, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2206.9202, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10892.7324, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6711.3896, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(834.5185, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1122.4255, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2224.3987, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11159.0957, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6660.7900, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(807.3125, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1350.8990, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2340.0938, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10837.0488, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6436.6895, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(838.1838, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1334.6663, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2227.5098, device='cuda:0', grad_fn=<MulBackward0>)}
[8:14579]  loss_total_vae=10956.225  loss_recon=6580.686  loss_kld=835.859  loss_prediction=1273.963  loss_true_values=2265.717  loss_total_vae_epoch=10923.077  
tracking changes
Saved model at epoch 9
Losses: {'total_vae': tensor(10970.0039, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6566.3486, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(852.0157, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1297.2651, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2254.3745, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11007.6465, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6720.3037, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(840.0711, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1206.6523, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2240.6196, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10898.3105, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6596.8862, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(826.4948, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1236.6556, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2238.2742, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10809.0703, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6401.5806, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(836.9269, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1411.6486, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2158.9138, device='cuda:0', grad_fn=<MulBackward0>)}
[9:16199]  loss_total_vae=10606.037  loss_recon=6327.587  loss_kld=851.981  loss_prediction=1296.564  loss_true_values=2129.904  loss_total_vae_epoch=10889.147  
tracking changes
Saved model at epoch 10
Losses: {'total_vae': tensor(10783.0225, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6579.3638, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(829.6463, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1208.8003, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2165.2122, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10793.7432, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6559.4253, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(856.9207, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1261.1531, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2116.2444, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(11124.2051, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6679.8037, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(843.1018, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1357.0939, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2244.2056, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10918.1543, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6636.3384, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(819.1647, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1235.8225, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2226.8293, device='cuda:0', grad_fn=<MulBackward0>)}
[10:17819]  loss_total_vae=10686.935  loss_recon=6299.499  loss_kld=838.029  loss_prediction=1370.472  loss_true_values=2178.936  loss_total_vae_epoch=10861.145  
tracking changes
Validation stop evaluation
17819 10
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
Saved model at epoch 11
Losses: {'total_vae': tensor(10738.1328, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6487.5469, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(841.9836, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1196.5903, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2212.0115, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10857.4482, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6599.7402, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(826.7432, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1272.2323, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2158.7322, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10696.9834, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6261.1060, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(837.6118, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1384.5181, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2213.7471, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10957.5332, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6528.4111, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(845.0214, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1341.1805, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2242.9199, device='cuda:0', grad_fn=<MulBackward0>)}
[11:19439]  loss_total_vae=10995.549  loss_recon=6717.470  loss_kld=808.215  loss_prediction=1171.488  loss_true_values=2298.375  loss_total_vae_epoch=10833.944  
tracking changes
Validation stop evaluation
19439 11
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
Now val counter at: 1
Latent 0.31470195609744234   0.31740380258056594
BCE 1.2789129160418369 1.300595209346746
Saved model at epoch 12
Losses: {'total_vae': tensor(10877.2549, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6575.6099, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(830.4816, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1279.3036, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2191.8606, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10897.6768, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6556.9888, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(847.9512, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1240.8950, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2251.8416, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10781.6250, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6516.1460, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(882.8503, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1196.7933, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2185.8359, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10799.7012, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6634.3496, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(803.9321, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1186.8281, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2174.5913, device='cuda:0', grad_fn=<MulBackward0>)}
[12:21059]  loss_total_vae=10837.973  loss_recon=6649.692  loss_kld=862.238  loss_prediction=1210.648  loss_true_values=2115.394  loss_total_vae_epoch=10810.536  
tracking changes
Validation stop evaluation
21059 12
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
Saved model at epoch 13
Losses: {'total_vae': tensor(10738.6387, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6543.3198, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(877.8513, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1170.1627, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2147.3052, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10651.9707, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6492.2773, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(829.8068, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1211.4646, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2118.4224, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10852.6895, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6551.4790, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(836.2811, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1230.7214, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2234.2083, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10776.7930, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6498.6138, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(837.3895, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1198.7196, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2242.0703, device='cuda:0', grad_fn=<MulBackward0>)}
[13:22679]  loss_total_vae=10975.798  loss_recon=6587.373  loss_kld=837.056  loss_prediction=1363.679  loss_true_values=2187.690  loss_total_vae_epoch=10789.770  
tracking changes
Validation stop evaluation
22679 13
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
Now val counter at: 1
Latent 0.31273847995418136   0.31514897322890784
BCE 1.2573350579431741 1.2823672782469897
Saved model at epoch 14
Losses: {'total_vae': tensor(10799.1211, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6528.1128, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(845.8567, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1230.6860, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2194.4644, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10853.8223, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6596.4048, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(827.7713, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1291.9969, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2137.6489, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10847.0137, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6645.0693, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(846.5107, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1183.4362, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2171.9971, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10666.7939, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6521.3711, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(818.1335, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1169.3286, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2157.9602, device='cuda:0', grad_fn=<MulBackward0>)}
[14:24299]  loss_total_vae=10730.602  loss_recon=6577.623  loss_kld=889.684  loss_prediction=1148.574  loss_true_values=2114.722  loss_total_vae_epoch=10772.395  
tracking changes
Validation stop evaluation
24299 14
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
Saved model at epoch 15
Losses: {'total_vae': tensor(10854.0859, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6495.8726, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(903.1061, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1309.6404, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2145.4668, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10595.5703, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6366.9395, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(856.6638, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1209.7000, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2162.2671, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10722.9580, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6502.6328, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(790.7360, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1188.7944, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2240.7947, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10717.2285, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6547.8555, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(844.5284, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1126.5605, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2198.2847, device='cuda:0', grad_fn=<MulBackward0>)}
[15:25919]  loss_total_vae=10887.299  loss_recon=6620.776  loss_kld=829.911  loss_prediction=1220.092  loss_true_values=2216.521  loss_total_vae_epoch=10752.526  
tracking changes
Validation stop evaluation
25919 15
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
Now val counter at: 1
Latent 0.3093872332927024   0.31212936213897796
BCE 1.2405775251364943 1.2644518220385308
Saved model at epoch 16
Losses: {'total_vae': tensor(10499.6260, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6426.0488, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(839.4083, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1107.5879, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2126.5813, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10638.0811, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6534.8599, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(848.5337, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1182.7793, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2071.9082, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10704.3652, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6484.1284, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(855.2716, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1263.8083, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2101.1567, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10726.3271, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6624.8638, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(849.9922, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1167.7167, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2083.7551, device='cuda:0', grad_fn=<MulBackward0>)}
[16:27539]  loss_total_vae=10732.249  loss_recon=6534.788  loss_kld=848.680  loss_prediction=1172.982  loss_true_values=2175.800  loss_total_vae_epoch=10737.145  
tracking changes
Validation stop evaluation
27539 16
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
Now val counter at: 1
Latent 0.3077116495016778   0.3087670083093171
BCE 1.2433931030849419 1.2526496584856077
Saved model at epoch 17
Losses: {'total_vae': tensor(10699.8076, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6516.5737, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.9141, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1139.2213, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2176.0986, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10871.7324, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6614.1060, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(811.3162, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1192.8737, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2253.4363, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10762.2207, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6637.3848, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(857.5106, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1121.7814, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2145.5435, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10841.4424, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6522.3794, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(851.5396, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1238.4886, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2229.0354, device='cuda:0', grad_fn=<MulBackward0>)}
[17:29159]  loss_total_vae=10527.131  loss_recon=6476.767  loss_kld=836.553  loss_prediction=1065.992  loss_true_values=2147.820  loss_total_vae_epoch=10720.417  
tracking changes
Validation stop evaluation
29159 17
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
Now val counter at: 1
Latent 0.31075730005113206   0.30891353595178117
BCE 1.238098377048379 1.2471396694875787
Losses: {'total_vae': tensor(10787.6846, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6608.7300, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(842.7233, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1136.3336, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2199.8972, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10558.7451, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6461.8413, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(826.3834, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1074.2039, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2196.3162, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10445.8574, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6347.6372, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(860.5187, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1092.2977, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2145.4043, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10563.8516, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6469.6685, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(838.4809, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1139.9526, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2115.7495, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
30779 18
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
Latent 0.30735102664716174   0.3072379258009467
BCE 1.2341790990074082 1.2424923512015011
Losses: {'total_vae': tensor(10616.0645, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6411.8438, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(885.3018, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1277.5627, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2041.3564, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10743.7207, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6558.5898, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(868.8538, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1211.1204, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2105.1565, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10618.6367, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6564.6812, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(825.9437, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1107.9012, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2120.1108, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10830.8145, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6591., device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(842.8903, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1201.9218, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2195.0024, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
32399 19
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
Latent 0.30582529483455245   0.30928539428183743
BCE 1.2227774218167409 1.2406896684232718
Saved model at epoch 20
Losses: {'total_vae': tensor(10590.6299, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6555.8267, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(852.8462, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1078.6166, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2103.3411, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10687.5605, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6457.8911, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(902.1911, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1200.3383, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2127.1409, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10795.6396, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6591.2974, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(806.1382, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1295.3365, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2102.8672, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10901.9629, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6549.9565, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(829.6783, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1300.3932, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2221.9346, device='cuda:0', grad_fn=<MulBackward0>)}
[20:34019]  loss_total_vae=10995.605  loss_recon=6719.849  loss_kld=851.425  loss_prediction=1270.603  loss_true_values=2153.728  loss_total_vae_epoch=10679.510  
tracking changes
Validation stop evaluation
34019 20
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
Saved model at epoch 21
Losses: {'total_vae': tensor(10522.8760, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6504.9287, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(864.0566, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1127.5043, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2026.3871, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10483.0430, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6467.6211, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(893.1233, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1091.5472, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2030.7520, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10705.6094, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6474.1040, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(825.9203, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1135.4886, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2270.0972, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10448.2939, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6547.8345, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(837.4912, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1009.0214, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2053.9470, device='cuda:0', grad_fn=<MulBackward0>)}
[21:35639]  loss_total_vae=10371.166  loss_recon=6560.503  loss_kld=867.582  loss_prediction=957.848  loss_true_values=1985.233  loss_total_vae_epoch=10665.978  
tracking changes
Validation stop evaluation
35639 21
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
Saved model at epoch 22
Losses: {'total_vae': tensor(10522.1777, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6475.8071, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(891.7587, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1150.5792, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2004.0326, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10652.0781, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6538.0747, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(858.7841, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1170.8634, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2084.3552, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10726.4150, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6549.6318, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(876.8495, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1267.6611, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2032.2723, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10504.6250, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6401.1504, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(862.7166, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1165.6421, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2075.1152, device='cuda:0', grad_fn=<MulBackward0>)}
[22:37259]  loss_total_vae=10844.229  loss_recon=6486.213  loss_kld=821.305  loss_prediction=1426.163  loss_true_values=2110.548  loss_total_vae_epoch=10653.383  
tracking changes
Validation stop evaluation
37259 22
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
Saved model at epoch 23
Losses: {'total_vae': tensor(10630.6113, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6573.4893, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(887.2503, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1099.9501, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2069.9214, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10493.4854, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6623.2588, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(834.6450, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(978.2597, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2057.3220, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10692.2627, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6610.5771, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(806.0033, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1064.7941, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2210.8879, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10712.9541, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6555.1187, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(871.1386, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1237.5535, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2049.1433, device='cuda:0', grad_fn=<MulBackward0>)}
[23:38879]  loss_total_vae=10816.138  loss_recon=6615.911  loss_kld=850.300  loss_prediction=1280.497  loss_true_values=2069.430  loss_total_vae_epoch=10640.434  
tracking changes
Validation stop evaluation
38879 23
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
Now val counter at: 1
Latent 0.3029549471517601   0.30468850437760747
BCE 1.2092287369293742 1.2205454408138892
Saved model at epoch 24
Losses: {'total_vae': tensor(10591.2793, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6631.6548, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(865.5695, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1058.7993, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2035.2556, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10617.0010, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6562.2617, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(828.8143, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1104.2933, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2121.6316, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10618.3174, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6592.4785, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(859.4183, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1144.6818, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2021.7382, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10804.6709, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6473.0112, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(841.2064, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1273.7189, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2216.7341, device='cuda:0', grad_fn=<MulBackward0>)}
[24:40499]  loss_total_vae=10869.684  loss_recon=6576.999  loss_kld=846.239  loss_prediction=1269.546  loss_true_values=2176.900  loss_total_vae_epoch=10629.607  
tracking changes
Validation stop evaluation
40499 24
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
Saved model at epoch 25
Losses: {'total_vae': tensor(10540.4844, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6460.0513, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(849.8665, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1163.2163, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2067.3499, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10520.1289, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6505.1772, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(866.2587, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1061.6711, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2087.0212, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10513.9541, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6508.3135, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(877.4804, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1060.9302, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2067.2295, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10826.7588, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6614.9824, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.9340, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1196.8967, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2146.9451, device='cuda:0', grad_fn=<MulBackward0>)}
[25:42119]  loss_total_vae=10536.444  loss_recon=6507.454  loss_kld=847.689  loss_prediction=1050.616  loss_true_values=2130.686  loss_total_vae_epoch=10618.742  
tracking changes
Validation stop evaluation
42119 25
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
Saved model at epoch 26
Losses: {'total_vae': tensor(10527.8154, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6541.0972, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.7779, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1062.3899, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2048.5508, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10464.7607, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6357.1997, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(863.7192, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1092.2946, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2151.5466, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10645.1875, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6586.5762, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.5228, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1144.7334, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2046.3555, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10642.8867, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6508.6406, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(868.7108, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1158.3359, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2107.1997, device='cuda:0', grad_fn=<MulBackward0>)}
[26:43739]  loss_total_vae=10590.512  loss_recon=6632.855  loss_kld=838.440  loss_prediction=1064.712  loss_true_values=2054.505  loss_total_vae_epoch=10608.615  
tracking changes
Validation stop evaluation
43739 26
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
Now val counter at: 1
Latent 0.3005176351802184   0.3021269004927217
BCE 1.206559132231344 1.2073772912568386
Saved model at epoch 27
Losses: {'total_vae': tensor(10861.3848, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6481.3936, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(858.0135, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1360.5271, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2161.4507, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10760.5996, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6682.8604, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(846.3351, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1147.0690, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2084.3350, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10465.3682, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6624.2241, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(879.7930, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(961.3389, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2000.0116, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10553.7070, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6389.6460, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(866.0739, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1167.1667, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2130.8206, device='cuda:0', grad_fn=<MulBackward0>)}
[27:45359]  loss_total_vae=10373.546  loss_recon=6527.167  loss_kld=876.989  loss_prediction=974.899  loss_true_values=1994.490  loss_total_vae_epoch=10596.744  
tracking changes
Validation stop evaluation
45359 27
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
Saved model at epoch 28
Losses: {'total_vae': tensor(10611.8750, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6521.0625, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.1255, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1188.2197, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2008.4672, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10773.7344, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6570.6460, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(848.1017, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1193.2579, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2161.7285, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10614.4492, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6607.1763, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(878.4169, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1099.6764, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2029.1801, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10771.0488, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6660.6274, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(887.9058, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1126.8972, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2095.6177, device='cuda:0', grad_fn=<MulBackward0>)}
[28:46979]  loss_total_vae=10278.486  loss_recon=6406.377  loss_kld=885.424  loss_prediction=991.241  loss_true_values=1995.444  loss_total_vae_epoch=10586.972  
tracking changes
Validation stop evaluation
46979 28
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
Now val counter at: 1
Latent 0.29599523588572396   0.30150144889016356
BCE 1.1990302550320577 1.2039500367720135
Saved model at epoch 29
Losses: {'total_vae': tensor(10434.5840, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6455.1519, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(900.0027, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(939.3509, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2140.0786, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10731.9590, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.0137, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(878.6982, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1321.5718, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2053.6753, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10440.1807, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6455.8486, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(898.0754, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1120.8682, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1965.3890, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10676.3203, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6548.2310, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.0826, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1199.1946, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2053.8120, device='cuda:0', grad_fn=<MulBackward0>)}
[29:48599]  loss_total_vae=10537.120  loss_recon=6546.870  loss_kld=870.237  loss_prediction=1106.736  loss_true_values=2013.276  loss_total_vae_epoch=10577.667  
tracking changes
Validation stop evaluation
48599 29
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
Now val counter at: 1
Latent 0.2997006208884834   0.30023445346371175
BCE 1.1918672426502304 1.2007794106754137
Saved model at epoch 30
Losses: {'total_vae': tensor(10469.0059, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6509.3750, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(873.1333, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1102.4606, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1984.0372, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10637.3701, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6651.4121, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.3360, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1066.9141, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2037.7076, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10653.6191, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6594.3604, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(847.1298, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1110.0696, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2102.0593, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10686.2842, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6618.1011, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(869.0151, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1196.1329, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2003.0354, device='cuda:0', grad_fn=<MulBackward0>)}
[30:50219]  loss_total_vae=10561.973  loss_recon=6574.119  loss_kld=901.079  loss_prediction=1053.944  loss_true_values=2032.832  loss_total_vae_epoch=10568.269  
tracking changes
Validation stop evaluation
50219 30
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
Now val counter at: 1
Latent 0.2992237700094091   0.29853059002275123
BCE 1.1996673912104994 1.199739722725582
Losses: {'total_vae': tensor(10681.1738, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.8481, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(877.8122, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1265.4331, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2059.0801, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10566.1904, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6544.2061, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(835.1265, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1013.5380, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2173.3201, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10268.0996, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6379.3223, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(829.1703, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(965.4860, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2094.1208, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10596.1797, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6680.2480, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(862.9795, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1124.2201, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1928.7322, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
51839 31
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
Now val counter at: 2
Latent 0.30060654258964087   0.2982582519255062
BCE 1.1882845564643936 1.194842426198544
Losses: {'total_vae': tensor(10478.5146, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6575.0542, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(868.8713, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1080.1284, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1954.4600, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10553.1846, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6533.9126, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.5972, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1030.2535, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2107.4209, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10681.7969, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6708.1909, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(882.6119, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1114.3044, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1976.6897, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10675.5215, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6519.0659, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(883.9004, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1217.1572, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2055.3987, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
53459 32
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
Now val counter at: 3
Latent 0.29817416703346933   0.2983065422612055
BCE 1.1884396052596593 1.1968549629642624
Saved model at epoch 33
Losses: {'total_vae': tensor(10350.7402, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6392.1855, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(882.0486, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(989.0682, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2087.4377, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10525.9189, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6608.3975, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.7897, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(993.8017, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2047.9305, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10665.2549, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6604.6973, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(901.8163, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1096.5955, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2062.1453, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10558.6592, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6468.6968, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(863.3506, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1155.6649, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2070.9475, device='cuda:0', grad_fn=<MulBackward0>)}
[33:55079]  loss_total_vae=10520.280  loss_recon=6579.958  loss_kld=867.725  loss_prediction=1034.542  loss_true_values=2038.054  loss_total_vae_epoch=10541.305  
tracking changes
Validation stop evaluation
55079 33
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
Saved model at epoch 34
Losses: {'total_vae': tensor(10538.3721, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6456.3799, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.0876, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1162.5100, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2038.3943, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10461.7666, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6366.7300, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(859.7616, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1153.5800, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2081.6956, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10465.9219, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6502.1030, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(871.9586, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1105.3175, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1986.5435, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10652.3359, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6384.1938, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.2896, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1229.5874, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2163.2651, device='cuda:0', grad_fn=<MulBackward0>)}
[34:56699]  loss_total_vae=10727.997  loss_recon=6530.438  loss_kld=896.386  loss_prediction=1197.205  loss_true_values=2103.969  loss_total_vae_epoch=10533.900  
tracking changes
Validation stop evaluation
56699 34
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
Saved model at epoch 35
Losses: {'total_vae': tensor(10555.1074, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6345.4736, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(912.1924, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1184.3146, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2113.1270, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10437.2383, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6550.8271, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.4138, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(999.8101, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1992.1876, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10542.9873, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6661.4248, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(874.0466, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1029.7098, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1977.8066, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10715.9824, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6520.1797, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.5390, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1188.3339, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2131.9297, device='cuda:0', grad_fn=<MulBackward0>)}
[35:58319]  loss_total_vae=10684.186  loss_recon=6493.186  loss_kld=878.034  loss_prediction=1241.104  loss_true_values=2071.862  loss_total_vae_epoch=10523.874  
tracking changes
Validation stop evaluation
58319 35
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
Now val counter at: 1
Latent 0.30007737402868745   0.29891314296045707
BCE 1.1860203226604085 1.1880943690589554
Losses: {'total_vae': tensor(10568.8408, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6414.1987, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(869.5939, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1131.3386, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2153.7097, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10339.0391, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6368.5537, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.4300, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1044.6652, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2044.3896, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10575.3926, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6468.1030, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(903.2585, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1188.0380, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2015.9934, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10441.6055, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6527.3062, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(860.8093, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(997.6479, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2055.8425, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
59939 36
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
Now val counter at: 2
Latent 0.3004562615758122   0.296717310551763
BCE 1.2026009907816897 1.1874138251586321
Losses: {'total_vae': tensor(10348.4697, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6434.0474, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(855.2947, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(970.4666, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2088.6611, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10482.5557, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6435.9282, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(875.8304, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1021.9987, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2148.7976, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10581.0381, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6555.8159, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(902.0614, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1103.6409, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2019.5197, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10547.1582, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6446.0098, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(850.1367, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1122.4468, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2128.5642, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
61559 37
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
Latent 0.29725996308987684   0.2973517128835024
BCE 1.1789110984542581 1.1866073976255487
Saved model at epoch 38
Losses: {'total_vae': tensor(10645.7109, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6559.3047, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.0137, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1065.9655, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2139.4270, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10497.9746, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6367.4648, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(882.0967, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1168.9694, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2079.4434, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10580.1787, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6682.8618, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.2155, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(995.1221, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2012.9797, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10307.9219, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6465.7949, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(911.1772, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(932.4150, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1998.5356, device='cuda:0', grad_fn=<MulBackward0>)}
[38:63179]  loss_total_vae=10693.173  loss_recon=6641.184  loss_kld=819.468  loss_prediction=1137.015  loss_true_values=2095.506  loss_total_vae_epoch=10500.346  
tracking changes
Validation stop evaluation
63179 38
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
Now val counter at: 1
Latent 0.30037576624072426   0.29818422698935265
BCE 1.1930708200624673 1.1916214127351743
Losses: {'total_vae': tensor(10634.1465, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6544.9023, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(862.5470, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1241.5834, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1985.1143, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10556.2305, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6474.9644, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.2722, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1140.3879, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2073.6067, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10588.4170, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6448.5200, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(876.8572, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1170.2378, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2092.8015, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10499.2666, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6466.6450, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(895.4857, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1124.7889, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2012.3470, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
64799 39
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
Latent 0.2981749027967453   0.29926453289812555
BCE 1.1898326938695247 1.1891774706321188
Saved model at epoch 40
Losses: {'total_vae': tensor(10595.0195, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6563.3979, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(877.0080, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1190.0955, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1964.5184, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10774.1797, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6488.4048, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(851.1750, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1301.6772, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2132.9221, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10196.7930, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6435.8926, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.0955, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(882.2001, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1984.6042, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10496.0332, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6469.5024, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(902.7680, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1113.4176, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2010.3445, device='cuda:0', grad_fn=<MulBackward0>)}
[40:66419]  loss_total_vae=10306.595  loss_recon=6451.373  loss_kld=868.552  loss_prediction=977.299  loss_true_values=2009.371  loss_total_vae_epoch=10485.165  
tracking changes
Validation stop evaluation
66419 40
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
Saved model at epoch 41
Losses: {'total_vae': tensor(10692.9033, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6719.7646, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(908.3640, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1047.3016, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2017.4734, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10484.0381, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6423.4585, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(880.7603, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1121.5605, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2058.2585, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10355.7852, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6377.3110, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.1775, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1052.2297, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2059.0671, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10514.4062, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6435.8813, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(891.7957, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1129.9917, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2056.7378, device='cuda:0', grad_fn=<MulBackward0>)}
[41:68039]  loss_total_vae=10547.978  loss_recon=6464.681  loss_kld=857.556  loss_prediction=1131.087  loss_true_values=2094.653  loss_total_vae_epoch=10479.477  
tracking changes
Validation stop evaluation
68039 41
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
Now val counter at: 1
Latent 0.2962731385585105   0.2986035440424488
BCE 1.1782593904155316 1.1872715374620835
Saved model at epoch 42
Losses: {'total_vae': tensor(10529.0889, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6553.9292, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(876.2302, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1051.3817, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2047.5481, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10504.3301, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6601.5493, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(891.3198, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(940.4959, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2070.9644, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10404.9609, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6424.3770, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(909.6716, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1035.8853, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2035.0272, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10322.8193, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6372.7388, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(857.5491, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1070.9847, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2021.5466, device='cuda:0', grad_fn=<MulBackward0>)}
[42:69659]  loss_total_vae=10425.949  loss_recon=6487.764  loss_kld=870.506  loss_prediction=1013.240  loss_true_values=2054.439  loss_total_vae_epoch=10472.461  
tracking changes
Validation stop evaluation
69659 42
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
Now val counter at: 1
Latent 0.2949793115995898   0.2978101057974812
BCE 1.1807943780233365 1.187377912573295
Saved model at epoch 43
Losses: {'total_vae': tensor(10550.2705, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6667.6572, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(897.7450, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(959.8911, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2024.9779, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10482.5225, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6505.2119, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(860.8423, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1042.3478, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2074.1199, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10542.7891, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.6567, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(878.6865, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1179.7606, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2005.6857, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10273.3750, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6517.7524, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(904.8084, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(876.2648, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1974.5483, device='cuda:0', grad_fn=<MulBackward0>)}
[43:71279]  loss_total_vae=10462.552  loss_recon=6628.292  loss_kld=877.539  loss_prediction=909.742  loss_true_values=2046.978  loss_total_vae_epoch=10466.359  
tracking changes
Validation stop evaluation
71279 43
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
Now val counter at: 1
Latent 0.29591245432891466   0.2964425632367433
BCE 1.181206918293887 1.18244076935765
Saved model at epoch 44
Losses: {'total_vae': tensor(10486.7246, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6556.7959, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(880.7952, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1036.8888, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2012.2441, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10602.0625, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6470.4819, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(915.4059, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1126.7269, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2089.4478, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10594.3740, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6496.2065, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(904.4008, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1180.1776, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2013.5887, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10513.8193, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6319.5234, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(938.3105, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1295.6915, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1960.2936, device='cuda:0', grad_fn=<MulBackward0>)}
[44:72899]  loss_total_vae=10504.453  loss_recon=6450.605  loss_kld=880.109  loss_prediction=1143.269  loss_true_values=2030.471  loss_total_vae_epoch=10459.043  
tracking changes
Validation stop evaluation
72899 44
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
Now val counter at: 1
Latent 0.2984534808904818   0.2953773661710248
BCE 1.1992846078211719 1.1794279974089203
Losses: {'total_vae': tensor(10447.1602, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6491.0347, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.3947, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1017.1948, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2052.5359, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10497.7627, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6556.3555, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(896.0119, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1009.2488, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2036.1462, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10664.8613, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6759.3569, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(843.4014, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1073.4155, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1988.6879, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10410.3594, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6543.7051, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(884.5879, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(990.0089, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1992.0573, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
74519 45
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
Latent 0.29612814273574567   0.295721634829005
BCE 1.1861829323933857 1.180086895577585
Losses: {'total_vae': tensor(10422.7021, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6393.7646, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(892.3675, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(997.2571, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2139.3123, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10740.9150, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6702.8257, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.3003, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1068.9152, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2082.8743, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10538.3164, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6468.0259, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(885.9775, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1133.1790, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2051.1333, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10558.5078, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6499.5234, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(867.5326, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1109.0476, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2082.4038, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
76139 46
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
Now val counter at: 2
Latent 0.2979649666807439   0.29644841560632873
BCE 1.1866445216802086 1.187095301379465
Losses: {'total_vae': tensor(10390.8984, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6554.5913, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(860.3400, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(938.3325, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2037.6349, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10437.2207, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6530.6367, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(909.6078, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1071.9799, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1924.9963, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10272.5957, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6280.1787, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.3389, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1080.0674, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2018.0112, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10561.1650, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6481.2969, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(863.3191, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1148.5283, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2068.0203, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
77759 47
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
Latent 0.2975847282917193   0.29683135931838067
BCE 1.1842182927792615 1.1888914861694815
Losses: {'total_vae': tensor(10643.7148, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6565.9062, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(892.5711, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1150.9655, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2034.2711, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10423.5684, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6397.9619, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(869.8017, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1123.5367, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2032.2681, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10248.3174, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6433.1035, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.6508, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(872.1111, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2053.4524, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10391.1787, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6562.4893, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(891.5988, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(980.1736, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1956.9169, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
79379 48
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
Latent 0.2946157551342898   0.2975155301023238
BCE 1.1790196326109443 1.1907040206315889
Saved model at epoch 49
Losses: {'total_vae': tensor(10564.2754, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6642.2847, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.6027, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1016.8583, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2018.5304, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10455.1357, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6430.3687, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(927.7012, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1119.4285, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1977.6381, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10634.9238, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6624.3325, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(898.3562, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1078.4828, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2033.7527, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10614.9678, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6659.5049, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(893.3502, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1073.1459, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1988.9666, device='cuda:0', grad_fn=<MulBackward0>)}
[49:80999]  loss_total_vae=10771.969  loss_recon=6510.672  loss_kld=940.055  loss_prediction=1296.804  loss_true_values=2024.438  loss_total_vae_epoch=10426.795  
tracking changes
Validation stop evaluation
80999 49
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
Now val counter at: 1
Latent 0.2913819787525895   0.29722594590273627
BCE 1.182160874699602 1.1856819156176186
Saved model at epoch 50
Losses: {'total_vae': tensor(10516.9473, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6410.6147, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(923.6199, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1175.7573, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2006.9556, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10665.5781, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6542.4824, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(893.2717, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1170.4493, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2059.3752, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10427.8262, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6629.5435, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(916.7500, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(945.3647, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1936.1681, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10286.6318, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6326.3311, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(911.0135, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(950.7885, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2098.4985, device='cuda:0', grad_fn=<MulBackward0>)}
[50:82619]  loss_total_vae=10594.421  loss_recon=6507.045  loss_kld=920.514  loss_prediction=1139.063  loss_true_values=2027.799  loss_total_vae_epoch=10419.816  
tracking changes
Validation stop evaluation
82619 50
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
Now val counter at: 1
Latent 0.2948836786027002   0.296721816702251
BCE 1.1902995203981306 1.1832941490234716
Saved model at epoch 51
Losses: {'total_vae': tensor(10365.2412, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6524.9912, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(898.7925, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(952.1373, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1989.3199, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10420.5674, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6625.8525, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.0309, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(939.4324, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1974.2518, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10307.9473, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.9722, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(904.8615, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(925.6012, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1998.5131, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10453.7441, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6536.8735, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(873.1792, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(957.5795, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2086.1125, device='cuda:0', grad_fn=<MulBackward0>)}
[51:84239]  loss_total_vae=10233.381  loss_recon=6460.330  loss_kld=903.523  loss_prediction=892.703  loss_true_values=1976.825  loss_total_vae_epoch=10414.931  
tracking changes
Validation stop evaluation
84239 51
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
Saved model at epoch 52
Losses: {'total_vae': tensor(10345.1113, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6531.7397, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(912.0131, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(973.9314, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1927.4263, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10308.2529, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6541.7861, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(910.1783, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(895.8087, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1960.4794, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10767.4297, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6725.5854, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(871.1451, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1085.4474, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2085.2517, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10432.9990, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6646.3838, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(845.0171, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(891.0348, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2050.5632, device='cuda:0', grad_fn=<MulBackward0>)}
[52:85859]  loss_total_vae=10578.956  loss_recon=6573.645  loss_kld=911.750  loss_prediction=1114.621  loss_true_values=1978.940  loss_total_vae_epoch=10408.581  
tracking changes
Validation stop evaluation
85859 52
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
Now val counter at: 1
Latent 0.2935954552180696   0.29362713749652647
BCE 1.192879680064645 1.1838266759028924
Saved model at epoch 53
Losses: {'total_vae': tensor(10206.2871, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6404.2393, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(906.6768, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(950.4067, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1944.9651, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10435.8438, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6554.2593, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(847.5802, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(951.4142, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2082.5901, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10301.2822, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6552.8359, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(931.2743, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(877.6815, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1939.4904, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10253.6182, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6498.8237, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(846.9675, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(875.4126, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2032.4149, device='cuda:0', grad_fn=<MulBackward0>)}
[53:87479]  loss_total_vae=10053.479  loss_recon=6295.501  loss_kld=906.756  loss_prediction=873.587  loss_true_values=1977.636  loss_total_vae_epoch=10402.847  
tracking changes
Validation stop evaluation
87479 53
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
Saved model at epoch 54
Losses: {'total_vae': tensor(10301.5117, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6511.1450, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(910.8945, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(930.4042, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1949.0687, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10333.8848, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6578.1230, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(838.2852, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(901.2805, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2016.1962, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10304.2920, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6434.8735, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(903.6262, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(904.9985, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2060.7939, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10342.8281, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6391.4565, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(885.4028, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1023.6983, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2042.2708, device='cuda:0', grad_fn=<MulBackward0>)}
[54:89099]  loss_total_vae=10195.815  loss_recon=6358.583  loss_kld=900.459  loss_prediction=908.226  loss_true_values=2028.547  loss_total_vae_epoch=10395.687  
tracking changes
Validation stop evaluation
89099 54
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
Now val counter at: 1
Latent 0.29321068067951955   0.2933777387287751
BCE 1.1873829816237536 1.1882832900132283
Saved model at epoch 55
Losses: {'total_vae': tensor(10347.3389, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.5586, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(914.7669, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(961.4688, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1992.5442, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10233.4102, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6439.8623, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(917.3474, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(964.8459, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1911.3545, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10487.1191, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6583.1030, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.9537, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(991.6908, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2017.3722, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10458.7178, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6542.1318, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(954.8641, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(999.5275, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1962.1945, device='cuda:0', grad_fn=<MulBackward0>)}
[55:90719]  loss_total_vae=10447.141  loss_recon=6669.987  loss_kld=897.149  loss_prediction=890.739  loss_true_values=1989.264  loss_total_vae_epoch=10390.972  
tracking changes
Validation stop evaluation
90719 55
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
Now val counter at: 1
Latent 0.2942923906415996   0.2924437939923982
BCE 1.1964743925203192 1.188023692605519
Losses: {'total_vae': tensor(10450.3916, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6467.8550, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(898.3865, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1050.4656, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2033.6849, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10734.7344, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6550.4468, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.3641, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1228.8828, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2066.0413, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10370.4814, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6443.7075, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.6249, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1047.8865, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1992.2623, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10455.3359, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6517.4497, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(893.8312, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1033.8154, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2010.2405, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
92339 56
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
Now val counter at: 2
Latent 0.29700610985850345   0.29296266009705296
BCE 1.19345957188323 1.1899277966211337
Losses: {'total_vae': tensor(10437.8252, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6522.4761, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(864.8431, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1027.3423, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2023.1633, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10506.1992, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6596.3682, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(890.3251, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1052.5670, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1966.9390, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10300.4570, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6486.1274, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(917.4796, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(950.0686, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1946.7815, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10657.6543, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6521.6172, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(890.3776, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1178.4979, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2067.1621, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
93959 57
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
Now val counter at: 3
Latent 0.29513619368029115   0.29319497190489624
BCE 1.1977238622632358 1.1911260341063585
Losses: {'total_vae': tensor(10177.4150, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6464.1865, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(911.2527, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(855.5306, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1946.4449, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10202.8174, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6444.5688, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(884.6652, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(940.1997, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1933.3839, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10524.5000, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6534.5488, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(896.8524, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1119.3660, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1973.7319, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10294.4326, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6564.2090, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(891.0742, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(887.1105, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1952.0388, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
95579 58
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
Now val counter at: 4
Latent 0.29587391830316867   0.29483639372654086
BCE 1.1998489625973277 1.192438982009101
Losses: {'total_vae': tensor(10538.7939, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6682.6050, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(878.4326, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(956.9391, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2020.8170, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10185.1992, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6404.7925, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(899.2583, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(887.1694, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1993.9786, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10369.6162, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6521.8335, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(897.5208, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(912.4521, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2037.8093, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10367.8555, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6524.1143, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(873.8889, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(911.1909, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2058.6624, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
97199 59
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
30   31.0  6527.050563  870.268759  0.299224  1.199667  0.887144
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
Now val counter at: 5
Latent 0.29410271036742935   0.29547823139346474
BCE 1.2003774238695013 1.1958859422222616
Saved model at epoch 60
Losses: {'total_vae': tensor(10115.4414, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6287.3896, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(902.6093, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(919.1740, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2006.2686, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10516.5654, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6659.9946, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(881.6956, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(968.7261, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2006.1497, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10524.3545, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6581.2598, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(872.8125, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1053.8423, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2016.4407, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(9912.0654, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6332.6812, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(926.8545, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(775.7798, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1876.7502, device='cuda:0', grad_fn=<MulBackward0>)}
[60:98819]  loss_total_vae=10298.441  loss_recon=6422.010  loss_kld=883.901  loss_prediction=1002.442  loss_true_values=1990.089  loss_total_vae_epoch=10360.877  
tracking changes
Validation stop evaluation
98819 60
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
31   32.0  6530.481173  856.650269  0.300607  1.188285  0.887256
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264

[61 rows x 6 columns]
Now val counter at: 1
Latent 0.2956013105588384   0.29600540728065444
BCE 1.1975456670959397 1.197010798914598
Saved model at epoch 61
Losses: {'total_vae': tensor(10304.3154, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6465.4487, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(901.9025, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(849.3535, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2087.6116, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10306.1553, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6508.9980, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.9535, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(917.1531, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1985.0507, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10229.4463, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6299.5435, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(897.2906, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1009.1257, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2023.4861, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10140.0342, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6335.7212, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(918.0781, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(900.7151, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1985.5194, device='cuda:0', grad_fn=<MulBackward0>)}
[61:100439]  loss_total_vae=10507.083  loss_recon=6638.358  loss_kld=889.275  loss_prediction=979.578  loss_true_values=1999.872  loss_total_vae_epoch=10355.078  
tracking changes
Validation stop evaluation
100439 61
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
32   33.0  6524.158834  879.336945  0.298174  1.188440  0.887325
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692

[62 rows x 6 columns]
Now val counter at: 1
Latent 0.2955076741700125   0.29503760745029645
BCE 1.2080182052484834 1.199316749576688
Losses: {'total_vae': tensor(10350.6475, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6515.8462, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(893.7313, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(977.3549, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1963.7151, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10305.8252, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6526.5161, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(921.8796, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(903.7498, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1953.6798, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10540.6660, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6635.5459, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.8695, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(934.7261, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2080.5242, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10183.0527, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6605.0288, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(906.2311, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(751.2793, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1920.5132, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
102059 62
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
33   34.0  6522.573419  876.565312  0.297959  1.187559  0.887232
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230

[63 rows x 6 columns]
Latent 0.29301273468697425   0.2951926464098122
BCE 1.1992748934443633 1.1992573511875897
Saved model at epoch 63
Losses: {'total_vae': tensor(10313.2705, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6544.7051, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.4617, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(881.3116, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2000.7917, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10525.2949, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6404.0063, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(912.2986, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1241.4152, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1967.5747, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10451.1689, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6525.9487, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(901.1866, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(964.9840, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2059.0500, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10454.7051, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6649.5703, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(906.1282, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(955.7538, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1943.2529, device='cuda:0', grad_fn=<MulBackward0>)}
[63:103679]  loss_total_vae=10397.772  loss_recon=6517.056  loss_kld=923.813  loss_prediction=985.540  loss_true_values=1971.363  loss_total_vae_epoch=10344.371  
tracking changes
Validation stop evaluation
103679 63
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
34   35.0  6520.385569  910.492952  0.294019  1.186243  0.888762
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984

[64 rows x 6 columns]
Now val counter at: 1
Latent 0.2935929183322604   0.29507056503209345
BCE 1.2132026585611966 1.2019804320713081
Saved model at epoch 64
Losses: {'total_vae': tensor(10476.1084, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6389.5835, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(886.8896, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1147.1376, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2052.4983, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10220.9443, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6611.6704, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(927.0544, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(782.4034, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1899.8163, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10374.9531, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6608.9111, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(928.3760, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(895.1113, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1942.5543, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10204.8555, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6554.7051, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(899.0966, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(834.0042, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1917.0497, device='cuda:0', grad_fn=<MulBackward0>)}
[64:105299]  loss_total_vae=10426.626  loss_recon=6554.197  loss_kld=926.683  loss_prediction=908.765  loss_true_values=2036.981  loss_total_vae_epoch=10339.688  
tracking changes
Validation stop evaluation
105299 64
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
35   36.0  6524.011095  858.767040  0.300077  1.186020  0.887941
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898

[65 rows x 6 columns]
Now val counter at: 1
Latent 0.2947901093428678   0.294707239805275
BCE 1.2025232309162026 1.2016129219295955
Losses: {'total_vae': tensor(10483.5703, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6546.7368, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(870.4720, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(996.9114, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2069.4504, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10432.4355, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6512.0859, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(888.8884, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1029.6215, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2001.8401, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10069.2012, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6435.9062, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.5800, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(815.2743, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1928.4401, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10604.8789, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6589.2788, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(862.4897, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(967.6506, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2185.4595, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
106919 65
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
36   37.0  6523.608778  867.453950  0.300456  1.202601  0.889004
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606

[66 rows x 6 columns]
Now val counter at: 2
Latent 0.2949700349628335   0.29403777572974904
BCE 1.213158881900334 1.2068319190846812
Losses: {'total_vae': tensor(10322.5078, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6511.5767, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(884.7712, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(935.6523, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1990.5083, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10341.5830, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6478.7124, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(884.4274, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(894.2346, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2084.2092, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10243.4824, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6414.6821, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(883.3721, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(950.8120, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1994.6166, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10238.4609, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6396.4648, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(931.3573, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1018.1600, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1892.4780, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
108539 66
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
37   38.0  6523.420990  872.848290  0.297260  1.178911  0.889119
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606
66   67.0  6513.903948  894.258664  0.294307  1.211778  0.892811

[67 rows x 6 columns]
Latent 0.29430686925897503   0.29379858745403414
BCE 1.2117776879579714 1.2050002609739208
Losses: {'total_vae': tensor(10247.0312, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6532.8042, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(868.9420, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(814.6504, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2030.6348, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10028.7803, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6368.5259, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(913.6619, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(762.9091, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1983.6836, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10418.5928, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6582.9844, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(883.8237, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(925.8083, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2025.9768, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10179.8887, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6401.2349, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(884.8527, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(897.7389, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1996.0623, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
110159 67
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
38   39.0  6530.067184  851.373310  0.300376  1.193071  0.886775
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606
66   67.0  6513.903948  894.258664  0.294307  1.211778  0.892811
67   68.0  6514.331597  902.409401  0.293514  1.217996  0.892847

[68 rows x 6 columns]
Now val counter at: 3
Latent 0.29351442432639624   0.29445102087932057
BCE 1.2179957454157349 1.2096282571259112
Saved model at epoch 68
Losses: {'total_vae': tensor(10422.3486, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6523.7124, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.2170, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(998.7654, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2005.6542, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10110.0879, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6426.2563, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(889.1960, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(849.0181, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1945.6172, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10311.4629, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6437.9351, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(861.5381, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1049.7416, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1962.2480, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10391.0947, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6435.0176, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(922.4911, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(959.1391, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2074.4475, device='cuda:0', grad_fn=<MulBackward0>)}
[68:111779]  loss_total_vae=10653.092  loss_recon=6659.445  loss_kld=903.473  loss_prediction=1123.191  loss_true_values=1966.982  loss_total_vae_epoch=10316.325  
tracking changes
Validation stop evaluation
111779 68
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
39   40.0  6522.294644  868.263575  0.298175  1.189833  0.889263
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606
66   67.0  6513.903948  894.258664  0.294307  1.211778  0.892811
67   68.0  6514.331597  902.409401  0.293514  1.217996  0.892847
68   69.0  6511.384839  887.926269  0.295200  1.211290  0.893336

[69 rows x 6 columns]
Now val counter at: 1
Latent 0.2951997427066954   0.29468900452155883
BCE 1.2112903901846102 1.209153266924836
Losses: {'total_vae': tensor(10161.2969, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6293.6919, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(898.0322, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(939.4089, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2030.1646, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10290.9443, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6412.0073, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(897.5641, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(960.2399, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2021.1329, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10381.3730, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6430.7573, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(903.3033, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(990.9185, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2056.3936, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10433.9404, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6458.5874, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(880.9753, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(1089.7451, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(2004.6328, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
113399 69
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
40   41.0  6515.344731  894.378771  0.294880  1.179230  0.890046
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606
66   67.0  6513.903948  894.258664  0.294307  1.211778  0.892811
67   68.0  6514.331597  902.409401  0.293514  1.217996  0.892847
68   69.0  6511.384839  887.926269  0.295200  1.211290  0.893336
69   70.0  6516.173376  877.931550  0.297167  1.217508  0.893230

[70 rows x 6 columns]
Now val counter at: 2
Latent 0.29716653325180015   0.2942637761827349
BCE 1.2175077686805535 1.2143107717580133
Losses: {'total_vae': tensor(10281.1709, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6498.7910, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(899.2249, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(929.7570, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1953.3975, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10202.4844, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6671.0234, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(894.7043, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(706.3073, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1930.4495, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10374.0977, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6527.5234, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(887.3517, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(975.2584, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1983.9644, device='cuda:0', grad_fn=<MulBackward0>)}
Losses: {'total_vae': tensor(10016.0420, device='cuda:0', grad_fn=<AddBackward0>), 'recon': tensor(6376.1719, device='cuda:0', grad_fn=<MulBackward0>), 'kld': tensor(922.8783, device='cuda:0', grad_fn=<MulBackward0>), 'prediction': tensor(790.3016, device='cuda:0', grad_fn=<MulBackward0>), 'true_values': tensor(1926.6896, device='cuda:0', grad_fn=<MulBackward0>)}
tracking changes
Validation stop evaluation
115019 70
    epoch          rec         kld    latent       bce       acc
0     1.0  6804.536569  708.075184  0.366700  1.831510  0.838688
1     2.0  6712.334793  789.640829  0.345178  1.593402  0.851396
2     3.0  6673.933091  779.078193  0.339746  1.485369  0.857537
3     4.0  6647.226250  812.133779  0.332879  1.430660  0.862472
4     5.0  6632.047153  789.527060  0.331694  1.382345  0.866100
5     6.0  6610.809097  803.952441  0.327145  1.355173  0.868458
6     7.0  6599.462039  802.147584  0.325208  1.330992  0.870912
7     8.0  6581.549007  823.483372  0.320864  1.313280  0.872619
8     9.0  6569.677463  860.929980  0.315106  1.296843  0.875322
9    10.0  6575.823815  834.637240  0.316242  1.291663  0.875086
10   11.0  6561.448394  845.249882  0.314503  1.276526  0.876908
11   12.0  6564.912290  836.019986  0.314702  1.278913  0.875444
12   13.0  6548.725730  875.431845  0.308948  1.257107  0.878815
13   14.0  6554.267243  835.442658  0.312738  1.257335  0.878981
14   15.0  6539.310096  901.037116  0.304615  1.243506  0.881088
15   16.0  6543.440316  850.013572  0.309387  1.240578  0.880087
16   17.0  6538.511126  860.073836  0.307712  1.243393  0.882225
17   18.0  6541.729403  841.056691  0.310757  1.238098  0.881162
18   19.0  6533.756590  854.219547  0.307351  1.234179  0.881260
19   20.0  6532.611074  857.755318  0.305825  1.222777  0.882883
20   21.0  6535.466197  863.999877  0.304610  1.221898  0.883679
21   22.0  6535.216689  864.996857  0.303630  1.216961  0.882834
22   23.0  6531.238397  882.856083  0.300546  1.209761  0.884263
23   24.0  6533.368530  860.035312  0.302955  1.209229  0.883395
24   25.0  6529.906105  861.387602  0.302880  1.203142  0.884622
25   26.0  6534.812048  868.183348  0.301107  1.202149  0.885325
26   27.0  6530.078942  870.129005  0.300518  1.206559  0.885646
27   28.0  6525.575860  881.957894  0.299079  1.193630  0.886288
28   29.0  6525.574938  902.567255  0.295995  1.199030  0.887148
29   30.0  6530.075724  869.768547  0.299701  1.191867  0.886667
..    ...          ...         ...       ...       ...       ...
41   42.0  6520.421037  878.093784  0.296273  1.178259  0.889698
42   43.0  6517.692574  887.843456  0.294979  1.180794  0.890585
43   44.0  6518.922983  882.494183  0.295912  1.181207  0.890094
44   45.0  6520.571609  872.720967  0.298453  1.199285  0.889940
45   46.0  6516.323048  881.664674  0.296128  1.186183  0.891095
46   47.0  6519.885545  866.571734  0.297965  1.186645  0.891017
47   48.0  6520.800121  866.433193  0.297585  1.184218  0.889918
48   49.0  6517.167946  885.573930  0.294616  1.179020  0.891470
49   50.0  6509.569873  919.735477  0.291382  1.182161  0.890986
50   51.0  6514.958537  889.176557  0.294884  1.190300  0.891171
51   52.0  6509.760155  916.449003  0.291654  1.181671  0.891522
52   53.0  6515.272912  902.018647  0.293595  1.192880  0.890999
53   54.0  6508.062686  917.326911  0.292082  1.189521  0.893193
54   55.0  6512.999551  896.729802  0.293211  1.187383  0.892372
55   56.0  6510.213075  900.811982  0.294292  1.196474  0.892013
56   57.0  6516.403351  876.287958  0.297006  1.193460  0.891960
57   58.0  6512.487020  888.594762  0.295136  1.197724  0.891621
58   59.0  6513.042336  882.181425  0.295874  1.199849  0.891782
59   60.0  6511.006033  898.428980  0.294103  1.200377  0.892973
60   61.0  6512.265984  886.741509  0.295601  1.197546  0.892264
61   62.0  6516.129118  885.593354  0.295508  1.208018  0.893692
62   63.0  6516.095303  899.335336  0.293013  1.199275  0.893230
63   64.0  6512.452450  910.074434  0.293593  1.213203  0.890984
64   65.0  6511.156207  890.568014  0.294790  1.202523  0.893898
65   66.0  6514.346925  890.655636  0.294970  1.213159  0.892606
66   67.0  6513.903948  894.258664  0.294307  1.211778  0.892811
67   68.0  6514.331597  902.409401  0.293514  1.217996  0.892847
68   69.0  6511.384839  887.926269  0.295200  1.211290  0.893336
69   70.0  6516.173376  877.931550  0.297167  1.217508  0.893230
70   71.0  6510.359192  914.053443  0.293053  1.226397  0.893652

[71 rows x 6 columns]
Now val counter at: 3
Latent 0.2930527901885533   0.29434034543068893
BCE 1.226396815906657 1.2136879411861055
Saved model at epoch 71
